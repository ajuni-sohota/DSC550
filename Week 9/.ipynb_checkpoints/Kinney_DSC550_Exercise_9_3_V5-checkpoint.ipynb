{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYRFxylc_gnj"
   },
   "source": [
    "## D. Kinney DSC 550 9.3 Exercise: Neural Network Classifiers\n",
    "\n",
    "1. **Neural Network Classifier with Scikit**\n",
    "\n",
    "Using the multi-label classifier dataset from earlier exercises (categorized-comments.jsonl in the reddit folder), fit a neural network classifier using scikit-learn. Use the code found in chapter 12 of the Applied Text Analysis with Python book as a guideline. Report the accuracy, precision, recall, F1-score, and confusion matrix.\n",
    "\n",
    "2. **Neural Network Classifier with Keras**\n",
    "\n",
    "Using the multi-label classifier dataset from earlier exercises (categorized-comments.jsonl in the reddit folder), fit a neural network classifier using Keras. Use the code found in chapter 12 of the Applied Text Analysis with Python book as a guideline. Report the accuracy, precision, recall, F1-score, and confusion matrix.\n",
    "\n",
    "3. **Classifying Images**\n",
    "\n",
    "In chapter 20 of the Machine Learning with Python Cookbook, implement the code found in section 20.15 classify MSINT images using a convolutional neural network. Report the accuracy of your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SttqQTDC_gnm"
   },
   "source": [
    "*********************************************\n",
    "#### 1. Neural Network Classifier with Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjrV41pU_gnp"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JXEj9sGL_gnz",
    "outputId": "530f34d4-3e54-4222-d85c-15de758b27f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606467, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/categorized-comments.csv')\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwAEdzc6NT94"
   },
   "outputs": [],
   "source": [
    "# This dataset is HUGE. Sample 50k observations...\n",
    "df = df.sample(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mgH64n1UNgXc",
    "outputId": "4ee55d23-bd9e-4b6c-fb50-c7d35d1ad338"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_games               35907\n",
       "sports                    12051\n",
       "science_and_technology     2042\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "ORcb0-6K_gn5",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "1cee190c-4ff4-46a4-b3c7-d4463ae61c20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 40312)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting features from text files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df.txt)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "h9qRkG-E_gn-",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "abdad09e-abc5-433f-c2b6-9e80f35e325f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 40312)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "o3pd9FAX_goM",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "eaa5363e-2e66-4a5d-be05-e13515e65d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.79446124\n",
      "Iteration 2, loss = 0.49173478\n",
      "Iteration 3, loss = 0.33787678\n",
      "Iteration 4, loss = 0.24978728\n",
      "Iteration 5, loss = 0.19366401\n",
      "Iteration 6, loss = 0.16098453\n",
      "Iteration 7, loss = 0.13905346\n",
      "Iteration 8, loss = 0.12439685\n",
      "Iteration 9, loss = 0.11334202\n",
      "Iteration 10, loss = 0.10444609\n",
      "Iteration 11, loss = 0.09775084\n",
      "Iteration 12, loss = 0.09112227\n",
      "Iteration 13, loss = 0.08522626\n",
      "Iteration 14, loss = 0.08111368\n",
      "Iteration 15, loss = 0.07752989\n",
      "Iteration 16, loss = 0.07493085\n",
      "Iteration 17, loss = 0.07181110\n",
      "Iteration 18, loss = 0.06996176\n",
      "Iteration 19, loss = 0.06777535\n",
      "Iteration 20, loss = 0.06585833\n",
      "Iteration 21, loss = 0.06449156\n",
      "Iteration 22, loss = 0.06370003\n",
      "Iteration 23, loss = 0.06169329\n",
      "Iteration 24, loss = 0.06087726\n",
      "Iteration 25, loss = 0.06074255\n",
      "Iteration 26, loss = 0.05992138\n",
      "Iteration 27, loss = 0.05899985\n",
      "Iteration 28, loss = 0.05824092\n",
      "Iteration 29, loss = 0.05697465\n",
      "Iteration 30, loss = 0.05701648\n",
      "Iteration 31, loss = 0.05650450\n",
      "Iteration 32, loss = 0.05646992\n",
      "Iteration 33, loss = 0.05579286\n",
      "Iteration 34, loss = 0.05569433\n",
      "Iteration 35, loss = 0.05483951\n",
      "Iteration 36, loss = 0.05456517\n",
      "Iteration 37, loss = 0.05422071\n",
      "Iteration 38, loss = 0.05502466\n",
      "Iteration 39, loss = 0.05391233\n",
      "Iteration 40, loss = 0.05393903\n",
      "Iteration 41, loss = 0.05303700\n",
      "Iteration 42, loss = 0.05274993\n",
      "Iteration 43, loss = 0.05266752\n",
      "Iteration 44, loss = 0.05300932\n",
      "Iteration 45, loss = 0.05260153\n",
      "Iteration 46, loss = 0.05281024\n",
      "Iteration 47, loss = 0.05241247\n",
      "Iteration 48, loss = 0.05302418\n",
      "Iteration 49, loss = 0.05220809\n",
      "Iteration 50, loss = 0.05199614\n",
      "Iteration 1, loss = 0.84640323\n",
      "Iteration 2, loss = 0.53166537\n",
      "Iteration 3, loss = 0.34698885\n",
      "Iteration 4, loss = 0.24997516\n",
      "Iteration 5, loss = 0.19738092\n",
      "Iteration 6, loss = 0.16442313\n",
      "Iteration 7, loss = 0.14143745\n",
      "Iteration 8, loss = 0.12537790\n",
      "Iteration 9, loss = 0.11314166\n",
      "Iteration 10, loss = 0.10350255\n",
      "Iteration 11, loss = 0.09474290\n",
      "Iteration 12, loss = 0.08778445\n",
      "Iteration 13, loss = 0.08242378\n",
      "Iteration 14, loss = 0.07785619\n",
      "Iteration 15, loss = 0.07423718\n",
      "Iteration 16, loss = 0.07085371\n",
      "Iteration 17, loss = 0.06859676\n",
      "Iteration 18, loss = 0.06685184\n",
      "Iteration 19, loss = 0.06510550\n",
      "Iteration 20, loss = 0.06301608\n",
      "Iteration 21, loss = 0.06253159\n",
      "Iteration 22, loss = 0.06112838\n",
      "Iteration 23, loss = 0.05981782\n",
      "Iteration 24, loss = 0.05900142\n",
      "Iteration 25, loss = 0.05892455\n",
      "Iteration 26, loss = 0.05803992\n",
      "Iteration 27, loss = 0.05817488\n",
      "Iteration 28, loss = 0.05668582\n",
      "Iteration 29, loss = 0.05573508\n",
      "Iteration 30, loss = 0.05591077\n",
      "Iteration 31, loss = 0.05481624\n",
      "Iteration 32, loss = 0.05484732\n",
      "Iteration 33, loss = 0.05465467\n",
      "Iteration 34, loss = 0.05402615\n",
      "Iteration 35, loss = 0.05380937\n",
      "Iteration 36, loss = 0.05358371\n",
      "Iteration 37, loss = 0.05365733\n",
      "Iteration 38, loss = 0.05333339\n",
      "Iteration 39, loss = 0.05308856\n",
      "Iteration 40, loss = 0.05311872\n",
      "Iteration 41, loss = 0.05307207\n",
      "Iteration 42, loss = 0.05239199\n",
      "Iteration 43, loss = 0.05289910\n",
      "Iteration 44, loss = 0.05240789\n",
      "Iteration 45, loss = 0.05149567\n",
      "Iteration 46, loss = 0.05235513\n",
      "Iteration 47, loss = 0.05202269\n",
      "Iteration 48, loss = 0.05205828\n",
      "Iteration 49, loss = 0.05220164\n",
      "Iteration 50, loss = 0.05184140\n",
      "Iteration 1, loss = 0.75177049\n",
      "Iteration 2, loss = 0.52127780\n",
      "Iteration 3, loss = 0.33784406\n",
      "Iteration 4, loss = 0.23955803\n",
      "Iteration 5, loss = 0.18760295\n",
      "Iteration 6, loss = 0.15869674\n",
      "Iteration 7, loss = 0.13939770\n",
      "Iteration 8, loss = 0.12719969\n",
      "Iteration 9, loss = 0.11744639\n",
      "Iteration 10, loss = 0.10999189\n",
      "Iteration 11, loss = 0.10445953\n",
      "Iteration 12, loss = 0.09910355\n",
      "Iteration 13, loss = 0.09380300\n",
      "Iteration 14, loss = 0.08924681\n",
      "Iteration 15, loss = 0.08578599\n",
      "Iteration 16, loss = 0.08279798\n",
      "Iteration 17, loss = 0.08003286\n",
      "Iteration 18, loss = 0.07809453\n",
      "Iteration 19, loss = 0.07492060\n",
      "Iteration 20, loss = 0.07317121\n",
      "Iteration 21, loss = 0.07193403\n",
      "Iteration 22, loss = 0.07005791\n",
      "Iteration 23, loss = 0.06944055\n",
      "Iteration 24, loss = 0.06746424\n",
      "Iteration 25, loss = 0.06633339\n",
      "Iteration 26, loss = 0.06615904\n",
      "Iteration 27, loss = 0.06482449\n",
      "Iteration 28, loss = 0.06421440\n",
      "Iteration 29, loss = 0.06361581\n",
      "Iteration 30, loss = 0.06257154\n",
      "Iteration 31, loss = 0.06221685\n",
      "Iteration 32, loss = 0.06184952\n",
      "Iteration 33, loss = 0.06125828\n",
      "Iteration 34, loss = 0.06053843\n",
      "Iteration 35, loss = 0.06035146\n",
      "Iteration 36, loss = 0.05977246\n",
      "Iteration 37, loss = 0.06001284\n",
      "Iteration 38, loss = 0.05940811\n",
      "Iteration 39, loss = 0.05887218\n",
      "Iteration 40, loss = 0.05891858\n",
      "Iteration 41, loss = 0.05849375\n",
      "Iteration 42, loss = 0.05785234\n",
      "Iteration 43, loss = 0.05755428\n",
      "Iteration 44, loss = 0.05748659\n",
      "Iteration 45, loss = 0.05746288\n",
      "Iteration 46, loss = 0.05796159\n",
      "Iteration 47, loss = 0.05641764\n",
      "Iteration 48, loss = 0.05721374\n",
      "Iteration 49, loss = 0.05679923\n",
      "Iteration 50, loss = 0.05642892\n",
      "Iteration 1, loss = 0.83988623\n",
      "Iteration 2, loss = 0.50174375\n",
      "Iteration 3, loss = 0.34246290\n",
      "Iteration 4, loss = 0.24904923\n",
      "Iteration 5, loss = 0.19211702\n",
      "Iteration 6, loss = 0.15897462\n",
      "Iteration 7, loss = 0.13775934\n",
      "Iteration 8, loss = 0.12331398\n",
      "Iteration 9, loss = 0.11209381\n",
      "Iteration 10, loss = 0.10431742\n",
      "Iteration 11, loss = 0.09677636\n",
      "Iteration 12, loss = 0.09045057\n",
      "Iteration 13, loss = 0.08569408\n",
      "Iteration 14, loss = 0.08174609\n",
      "Iteration 15, loss = 0.07724470\n",
      "Iteration 16, loss = 0.07418967\n",
      "Iteration 17, loss = 0.07258928\n",
      "Iteration 18, loss = 0.06887534\n",
      "Iteration 19, loss = 0.06745307\n",
      "Iteration 20, loss = 0.06593448\n",
      "Iteration 21, loss = 0.06454462\n",
      "Iteration 22, loss = 0.06383105\n",
      "Iteration 23, loss = 0.06245717\n",
      "Iteration 24, loss = 0.06232102\n",
      "Iteration 25, loss = 0.06076826\n",
      "Iteration 26, loss = 0.06073293\n",
      "Iteration 27, loss = 0.05979837\n",
      "Iteration 28, loss = 0.05980456\n",
      "Iteration 29, loss = 0.05906859\n",
      "Iteration 30, loss = 0.05864046\n",
      "Iteration 31, loss = 0.05778440\n",
      "Iteration 32, loss = 0.05762547\n",
      "Iteration 33, loss = 0.05738491\n",
      "Iteration 34, loss = 0.05666195\n",
      "Iteration 35, loss = 0.05644466\n",
      "Iteration 36, loss = 0.05677552\n",
      "Iteration 37, loss = 0.05673844\n",
      "Iteration 38, loss = 0.05636866\n",
      "Iteration 39, loss = 0.05612864\n",
      "Iteration 40, loss = 0.05547346\n",
      "Iteration 41, loss = 0.05612926\n",
      "Iteration 42, loss = 0.05533651\n",
      "Iteration 43, loss = 0.05481820\n",
      "Iteration 44, loss = 0.05527966\n",
      "Iteration 45, loss = 0.05446034\n",
      "Iteration 46, loss = 0.05475204\n",
      "Iteration 47, loss = 0.05568749\n",
      "Iteration 48, loss = 0.05479463\n",
      "Iteration 49, loss = 0.05447072\n",
      "Iteration 50, loss = 0.05447093\n",
      "Iteration 1, loss = 0.71467018\n",
      "Iteration 2, loss = 0.49408813\n",
      "Iteration 3, loss = 0.31117461\n",
      "Iteration 4, loss = 0.22613256\n",
      "Iteration 5, loss = 0.18171389\n",
      "Iteration 6, loss = 0.15683989\n",
      "Iteration 7, loss = 0.14030158\n",
      "Iteration 8, loss = 0.12894919\n",
      "Iteration 9, loss = 0.11994276\n",
      "Iteration 10, loss = 0.11374180\n",
      "Iteration 11, loss = 0.10834976\n",
      "Iteration 12, loss = 0.10426023\n",
      "Iteration 13, loss = 0.10041975\n",
      "Iteration 14, loss = 0.09712552\n",
      "Iteration 15, loss = 0.09424468\n",
      "Iteration 16, loss = 0.09124681\n",
      "Iteration 17, loss = 0.08997875\n",
      "Iteration 18, loss = 0.08763277\n",
      "Iteration 19, loss = 0.08591238\n",
      "Iteration 20, loss = 0.08432620\n",
      "Iteration 21, loss = 0.08324090\n",
      "Iteration 22, loss = 0.08149758\n",
      "Iteration 23, loss = 0.08019981\n",
      "Iteration 24, loss = 0.07901046\n",
      "Iteration 25, loss = 0.07840567\n",
      "Iteration 26, loss = 0.07688286\n",
      "Iteration 27, loss = 0.07627743\n",
      "Iteration 28, loss = 0.07546204\n",
      "Iteration 29, loss = 0.07472155\n",
      "Iteration 30, loss = 0.07455256\n",
      "Iteration 31, loss = 0.07365998\n",
      "Iteration 32, loss = 0.07193820\n",
      "Iteration 33, loss = 0.07248230\n",
      "Iteration 34, loss = 0.07149145\n",
      "Iteration 35, loss = 0.07035919\n",
      "Iteration 36, loss = 0.06948240\n",
      "Iteration 37, loss = 0.06966377\n",
      "Iteration 38, loss = 0.06879972\n",
      "Iteration 39, loss = 0.06878949\n",
      "Iteration 40, loss = 0.06880956\n",
      "Iteration 41, loss = 0.06727987\n",
      "Iteration 42, loss = 0.06684751\n",
      "Iteration 43, loss = 0.06665889\n",
      "Iteration 44, loss = 0.06640635\n",
      "Iteration 45, loss = 0.06602316\n",
      "Iteration 46, loss = 0.06497357\n",
      "Iteration 47, loss = 0.06489858\n",
      "Iteration 48, loss = 0.06421255\n",
      "Iteration 49, loss = 0.06386201\n",
      "Iteration 50, loss = 0.06314003\n",
      "Iteration 1, loss = 0.72818001\n",
      "Iteration 2, loss = 0.43410786\n",
      "Iteration 3, loss = 0.28791367\n",
      "Iteration 4, loss = 0.21824381\n",
      "Iteration 5, loss = 0.18001026\n",
      "Iteration 6, loss = 0.15589286\n",
      "Iteration 7, loss = 0.13877645\n",
      "Iteration 8, loss = 0.12587528\n",
      "Iteration 9, loss = 0.11420441\n",
      "Iteration 10, loss = 0.10509871\n",
      "Iteration 11, loss = 0.09668498\n",
      "Iteration 12, loss = 0.09030654\n",
      "Iteration 13, loss = 0.08601471\n",
      "Iteration 14, loss = 0.08194650\n",
      "Iteration 15, loss = 0.07770947\n",
      "Iteration 16, loss = 0.07462123\n",
      "Iteration 17, loss = 0.07273746\n",
      "Iteration 18, loss = 0.07095598\n",
      "Iteration 19, loss = 0.06820848\n",
      "Iteration 20, loss = 0.06754326\n",
      "Iteration 21, loss = 0.06600851\n",
      "Iteration 22, loss = 0.06497580\n",
      "Iteration 23, loss = 0.06409748\n",
      "Iteration 24, loss = 0.06253077\n",
      "Iteration 25, loss = 0.06200701\n",
      "Iteration 26, loss = 0.06131556\n",
      "Iteration 27, loss = 0.06113308\n",
      "Iteration 28, loss = 0.06076454\n",
      "Iteration 29, loss = 0.05965048\n",
      "Iteration 30, loss = 0.05901259\n",
      "Iteration 31, loss = 0.05860955\n",
      "Iteration 32, loss = 0.05860617\n",
      "Iteration 33, loss = 0.05877227\n",
      "Iteration 34, loss = 0.05819043\n",
      "Iteration 35, loss = 0.05731126\n",
      "Iteration 36, loss = 0.05722870\n",
      "Iteration 37, loss = 0.05750346\n",
      "Iteration 38, loss = 0.05659524\n",
      "Iteration 39, loss = 0.05650896\n",
      "Iteration 40, loss = 0.05617616\n",
      "Iteration 41, loss = 0.05617310\n",
      "Iteration 42, loss = 0.05628043\n",
      "Iteration 43, loss = 0.05579596\n",
      "Iteration 44, loss = 0.05504443\n",
      "Iteration 45, loss = 0.05496825\n",
      "Iteration 46, loss = 0.05556881\n",
      "Iteration 47, loss = 0.05522980\n",
      "Iteration 48, loss = 0.05462309\n",
      "Iteration 49, loss = 0.05494491\n",
      "Iteration 50, loss = 0.05418834\n"
     ]
    }
   ],
   "source": [
    "# Performance of MLP Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.txt, df.cat, test_size=0.33, random_state=42)\n",
    "\n",
    "# Consolidate steps into a pipeline...\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('ann', MLPClassifier(hidden_layer_sizes=[30,30],\n",
    "                          max_iter=50, \n",
    "                          verbose = True))]) \n",
    "scoring = 'f1_micro'\n",
    "scores = cross_val_score(text_clf, X_train, y_train, scoring=scoring)\n",
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "Helxe7PNpFz7",
    "outputId": "80b47bd8-4045-4131-a4e1-43b9e3e08370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 scores: [0.78656716 0.78626866 0.79477612 0.79119403 0.78597015]\n",
      "Accuracy:  0.7901212121212121\n",
      "Confusion Matrix:\n",
      " [[  274    45   343]\n",
      " [   53  2206  1740]\n",
      " [  192  1090 10557]]\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "science_and_technology       0.53      0.41      0.46       662\n",
      "                sports       0.66      0.55      0.60      3999\n",
      "           video_games       0.84      0.89      0.86     11839\n",
      "\n",
      "              accuracy                           0.79     16500\n",
      "             macro avg       0.67      0.62      0.64     16500\n",
      "          weighted avg       0.78      0.79      0.78     16500\n",
      "\n",
      "Accuracy:  0.7901212121212121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(f\"f1 scores: {scores}\")\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(\"Accuracy: \", np.mean(predicted == y_test))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predicted))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test,predicted))\n",
    "print(\"Accuracy: \", accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHfnMS4N_goS"
   },
   "source": [
    "*********************************************\n",
    "#### 2. Neural Network Classifier with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4MVgGgw_goU",
    "outputId": "6334440e-94f9-4e32-fd83-f9279e4b64de"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense \n",
    "from keras.models import Sequential \n",
    "\n",
    "N_FEATURES = 32791\n",
    "N_CLASSES = 3\n",
    "\n",
    "def build_network():\n",
    "    \"\"\" \n",
    "    Create a function that returns a compiled neural network \n",
    "    \"\"\" \n",
    "    nn = Sequential() \n",
    "    nn.add( Dense(30, activation ='relu', input_shape =( N_FEATURES,))) \n",
    "    nn.add( Dense(30, activation ='relu')) \n",
    "    nn.add( Dense(N_CLASSES, activation ='softmax')) \n",
    "    nn.compile( \n",
    "        loss ='categorical_crossentropy', \n",
    "        optimizer ='adam', \n",
    "        metrics =['accuracy'] ) \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8yXphAyW_goa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "33500/33500 [==============================] - 13s 395us/step - loss: 0.6339 - accuracy: 0.7582\n",
      "Epoch 2/20\n",
      "33500/33500 [==============================] - 13s 394us/step - loss: 0.3422 - accuracy: 0.8666\n",
      "Epoch 3/20\n",
      "33500/33500 [==============================] - 13s 390us/step - loss: 0.2373 - accuracy: 0.9097\n",
      "Epoch 4/20\n",
      "33500/33500 [==============================] - 13s 400us/step - loss: 0.1874 - accuracy: 0.9289\n",
      "Epoch 5/20\n",
      "33500/33500 [==============================] - 13s 398us/step - loss: 0.1589 - accuracy: 0.9396\n",
      "Epoch 6/20\n",
      "33500/33500 [==============================] - 13s 398us/step - loss: 0.1394 - accuracy: 0.9474\n",
      "Epoch 7/20\n",
      "33500/33500 [==============================] - 13s 397us/step - loss: 0.1240 - accuracy: 0.9528\n",
      "Epoch 8/20\n",
      "33500/33500 [==============================] - 14s 404us/step - loss: 0.1106 - accuracy: 0.9575\n",
      "Epoch 9/20\n",
      "33500/33500 [==============================] - 14s 403us/step - loss: 0.1002 - accuracy: 0.9618\n",
      "Epoch 10/20\n",
      "33500/33500 [==============================] - 13s 400us/step - loss: 0.0924 - accuracy: 0.9653\n",
      "Epoch 11/20\n",
      "33500/33500 [==============================] - 13s 400us/step - loss: 0.0850 - accuracy: 0.9674\n",
      "Epoch 12/20\n",
      "33500/33500 [==============================] - 13s 399us/step - loss: 0.0789 - accuracy: 0.9702\n",
      "Epoch 13/20\n",
      "33500/33500 [==============================] - 13s 399us/step - loss: 0.0750 - accuracy: 0.9712\n",
      "Epoch 14/20\n",
      "33500/33500 [==============================] - 13s 399us/step - loss: 0.0714 - accuracy: 0.9732\n",
      "Epoch 15/20\n",
      "33500/33500 [==============================] - 13s 402us/step - loss: 0.0689 - accuracy: 0.9744\n",
      "Epoch 16/20\n",
      "33500/33500 [==============================] - 13s 401us/step - loss: 0.0661 - accuracy: 0.9750\n",
      "Epoch 17/20\n",
      "33500/33500 [==============================] - 13s 402us/step - loss: 0.0645 - accuracy: 0.9758\n",
      "Epoch 18/20\n",
      "33500/33500 [==============================] - 14s 406us/step - loss: 0.0637 - accuracy: 0.9760\n",
      "Epoch 19/20\n",
      "33500/33500 [==============================] - 13s 403us/step - loss: 0.0618 - accuracy: 0.9766\n",
      "Epoch 20/20\n",
      "33500/33500 [==============================] - 14s 407us/step - loss: 0.0607 - accuracy: 0.9773\n",
      "[nan nan nan nan nan]\n",
      "0.7998181818181819\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "keras_clf = Pipeline([ \n",
    "    ('tfid', TfidfVectorizer( max_features = N_FEATURES)), \n",
    "    ('nn', KerasClassifier( build_fn = build_network, \n",
    "                            epochs = 20, \n",
    "                            batch_size = 128))\n",
    "])\n",
    "\n",
    "scores = cross_val_score(keras_clf, X_train, y_train, scoring ='accuracy', n_jobs =-1) \n",
    "keras_clf.fit(X_train, y_train) \n",
    "print(scores)\n",
    "keras_predicted = keras_clf.predict(X_test)\n",
    "print(np.mean(keras_predicted == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[  278    51   333]\n",
      " [   44  2410  1545]\n",
      " [  155  1175 10509]]\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "science_and_technology       0.58      0.42      0.49       662\n",
      "                sports       0.66      0.60      0.63      3999\n",
      "           video_games       0.85      0.89      0.87     11839\n",
      "\n",
      "              accuracy                           0.80     16500\n",
      "             macro avg       0.70      0.64      0.66     16500\n",
      "          weighted avg       0.79      0.80      0.80     16500\n",
      "\n",
      "Accuracy:  0.7998181818181819\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, keras_predicted))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test,keras_predicted))\n",
    "print(\"Accuracy: \", accuracy_score(y_test,keras_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MuL_SsAH_god"
   },
   "source": [
    "*********************************************\n",
    "#### 3. Classifying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKf3WIAx_gof",
    "outputId": "90256cbf-b761-40c9-9722-84d1e46ebaf2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "# Set that the color channel value will be first\n",
    "K.set_image_data_format(\"channels_first\")\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set image information\n",
    "channels = 1\n",
    "height = 28\n",
    "width = 28\n",
    "\n",
    "# Load data and target from MNIST data\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()\n",
    "\n",
    "# Reshape training image data into features\n",
    "data_train = data_train.reshape(data_train.shape[0], channels, height, width)\n",
    "\n",
    "# Reshape test image data into features\n",
    "data_test = data_test.reshape(data_test.shape[0], channels, height, width)\n",
    "\n",
    "# Rescale pixel intensity to between 0 and 1\n",
    "features_train = data_train / 255\n",
    "features_test = data_test / 255\n",
    "\n",
    "# One-hot encode target\n",
    "target_train = np_utils.to_categorical(target_train)\n",
    "target_test = np_utils.to_categorical(target_test)\n",
    "number_of_classes = target_test.shape[1]\n",
    "\n",
    "# Start neural network\n",
    "network = Sequential()\n",
    "\n",
    "# Add convolutional layer with 64 filters, a 5x5 window, and ReLU activation function\n",
    "network.add(Conv2D(filters=64,\n",
    "                   kernel_size=(5, 5),\n",
    "                   input_shape=(channels, width, height),\n",
    "                   activation='relu'))\n",
    "\n",
    "# Add max pooling layer with a 2x2 window\n",
    "network.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# Add layer to flatten input\n",
    "network.add(Flatten())\n",
    "\n",
    "# # Add fully connected layer of 128 units with a ReLU activation function\n",
    "network.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(Dense(number_of_classes, activation=\"softmax\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"categorical_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Train neural network\n",
    "network.fit(features_train, # Features\n",
    "            target_train, # Target\n",
    "            epochs=2, # Number of epochs\n",
    "            verbose=0, # Don't print description after each epoch\n",
    "\n",
    "batch_size=1000, # Number of observations per batch\n",
    "            validation_data=(features_test, target_test)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RCrWZs6_gom",
    "outputId": "c36fe091-8bee-416b-f4b1-6e99483b2cef"
   },
   "outputs": [],
   "source": [
    "score = network.evaluate(features_test, target_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJZBLIzm_gop"
   },
   "source": [
    "*************************\n",
    "**Additional References**\n",
    "\n",
    "Machine Learning, NLP: Text Classification using scikit-learn, python and NLTK. Jul 23, 2017\n",
    "https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kinney_DSC550_Exercise_9_3_V5.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
